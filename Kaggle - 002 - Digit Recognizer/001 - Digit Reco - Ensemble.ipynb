{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
    "\n",
    "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\n",
    "\n",
    "000 001 002 003 ... 026 027\n",
    "028 029 030 031 ... 054 055\n",
    "056 057 058 059 ... 082 083\n",
    " |   |   |   |  ...  |   |\n",
    "728 729 730 731 ... 754 755\n",
    "756 757 758 759 ... 782 783 \n",
    "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
    "\n",
    "Your submission file should be in the following format: For each of the 28000 images in the test set, output a single line containing the ImageId and the digit you predict. For example, if you predict that the first image is of a 3, the second image is of a 7, and the third image is of a 8, then your submission file would look like:\n",
    "\n",
    "ImageId,Label\n",
    "1,3\n",
    "2,7\n",
    "3,8 \n",
    "(27997 more lines)\n",
    "The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pylab import plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', delimiter=',', header=0)\n",
    "test = pd.read_csv('./data/test.csv', delimiter=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for index, row in train.iterrows():\n",
    "#    key = row['label']\n",
    "#    print('Label: ',str(key))\n",
    "#    data = np.array(row[1:]).reshape((28, 28))\n",
    "#    plt.imshow(data, cmap=plt.get_cmap('gray'))\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train['img'] = train.apply(lambda row: np.array(row[1:]).reshape((28, 28)), axis=1)\n",
    "\n",
    "# Unfortunately it's not possible to store a 2d array in a Serie of pandas dataframe,\n",
    "# I would require to use a Panel (i.e. Dataframe of Dataframe, I don't see how to do that with Scikit easily)\n",
    "# So hopefully neural network model can take a row as input and interpret that as a 28x28 image array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open questions:\n",
    "- How to not trip the ML classifier when the digit is in a corner and not in the center ?\n",
    "- What if colors are inverted ?\n",
    "\n",
    "Ideas :\n",
    "- Generate more data by translating data to the left/right/up/down\n",
    "- Sharpen the image and add to the data with opencv/imagemagick\n",
    "- scale up or down the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier, StackingClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_xgb = XGBClassifier( #0.88 - n = 30 - no feature scaling\n",
    "        n_estimators=30,\n",
    "        )\n",
    "clf_rf = RandomForestClassifier( #0.959 - n = 30 - no feature scaling\n",
    "        n_estimators=30,\n",
    "        n_jobs=-1,\n",
    "        )\n",
    "clf_et = ExtraTreesClassifier( #0.971 - n=1000 - no feature scaling\n",
    "        n_estimators=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=1\n",
    "        )\n",
    "clf_svc = SVC() #0.96 No multiproc, superlong to train (or BLAS issue ?)\n",
    "clf_lr = LogisticRegression(n_jobs=-1) \n",
    "clf_nb = GaussianNB()\n",
    "clf_kn = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "stack_et = ExtraTreesClassifier()\n",
    "\n",
    "clf_stack = StackingClassifier([clf_et, clf_xgb, clf_rf, clf_svc, clf_lr, clf_nb, clf_kn],stack_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurelist = (''.join(['pixel',str(i)]) for i in range(784))\n",
    "#featurelist generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper(\n",
    "    [ ([pixel], StandardScaler()) for pixel in featurelist]\n",
    ")\n",
    "# Do we need StandardScaler() ? It's the same scale of color for all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"featurize\", mapper),\n",
    "#    (\"extratrees\", clf_et)\n",
    "#   (\"xgboost\", clf_xgb)\n",
    "#   (\"randomforest\",clf_rf)\n",
    "#   (\"supportvector\",clf_svc)\n",
    "#   (\"logit\",clf_lr) #Best for binary classification so ignore\n",
    "#   (\"gauss\",clf_nb) #Naive_Bayes assume strong feature independance\n",
    "#   (\"kn\",clf_kn)\n",
    "    (\"stacking\", clf_stack)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################Helper functions ################\n",
    "##### Cross Validation\n",
    "def crossval():\n",
    "    # split = ShuffleSplit(n_splits=10) #compat issue with sklearn pandas \"object is not iterable\"\n",
    "    cv = cross_val_score(pipe, X_train, y_train, cv=10, n_jobs=-1)\n",
    "    print(\"Cross Validation Scores are: \", cv.round(3))\n",
    "    print(\"Mean CrossVal score is: \", round(cv.mean(),3))\n",
    "    print(\"Std Dev CrossVal score is: \", round(cv.std(),3))\n",
    "    return cv\n",
    "def output():\n",
    "    # predictions = pipe.predict(test)\n",
    "    result = pd.DataFrame(predictions)\n",
    "    result.index+=1\n",
    "    result.index.names=['ImageId']\n",
    "    result.columns=['Label']\n",
    "    result.to_csv(time.strftime(\"%Y-%m-%d_%H%M-\") + 'stacking.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# temp_cv = crossval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('featurize', DataFrameMapper(default=False,\n",
       "        features=[(['pixel0'], StandardScaler(copy=True, with_mean=True, with_std=True)), (['pixel1'], StandardScaler(copy=True, with_mean=True, with_std=True)), (['pixel2'], StandardScaler(copy=True, with_mean=True, with_std=True)), (['pixel3'], S...random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       "          use_probas=False, verbose=0))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
